{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6546357b-1b11-4313-aae5-7f49428a4206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d43fa21-dfd7-44b1-b1d7-87b3af2f7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로드 및 처리\n",
    "data = read_csv('price data.csv', sep=',')\n",
    "xy = data[['avgTemp', 'minTemp', 'maxTemp', 'rainFall', 'avgPrice']].to_numpy()\n",
    "\n",
    "x_data = xy[:, :-1]  # 평균 기온, 최저 기온, 최고 기온, 강수량\n",
    "y_data = xy[:, [-1]]  # 평균 가격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e178213-7f86-4ed6-be89-8a25b0af9eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "scaler = StandardScaler()\n",
    "x_data = scaler.fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a066922-9998-49e2-8d6f-b3a87d9e71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8169732f-7d31-4ee8-b17b-544cb337aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치와 편향 초기화 \n",
    "W = tf.Variable(tf.random.normal([4, 1], dtype=tf.float32), name=\"weight\")\n",
    "b = tf.Variable(tf.random.normal([1], dtype=tf.float32), name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4158ee08-3644-4e3b-8736-262a894e711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설 설정\n",
    "def hypothesis(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "# 손실 함수\n",
    "def cost_fn(X, Y):\n",
    "    cost = tf.reduce_mean(tf.square(hypothesis(X) - Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "072b2dc1-a6b9-4f98-a4cb-37a2246b0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a26daaa-c695-4a46-a445-ee01452a1d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 6197438.5, 예측 값: [0.28444517]\n",
      "Step 500, Loss: 5105195.0, 예측 값: [242.22945]\n",
      "Step 1000, Loss: 4212131.5, 예측 값: [459.8625]\n",
      "Step 1500, Loss: 3481618.0, 예측 값: [655.826]\n",
      "Step 2000, Loss: 2883897.0, 예측 값: [832.4272]\n",
      "Step 2500, Loss: 2394736.5, 예측 값: [991.6902]\n",
      "Step 3000, Loss: 1994362.75, 예측 값: [1135.4022]\n",
      "Step 3500, Loss: 1666631.75, 예측 값: [1265.1443]\n",
      "Step 4000, Loss: 1398348.125, 예측 값: [1382.3204]\n",
      "Step 4500, Loss: 1178719.5, 예측 값: [1488.1827]\n",
      "Step 5000, Loss: 998915.6875, 예측 값: [1583.8503]\n",
      "Step 5500, Loss: 851714.0625, 예측 값: [1670.3237]\n",
      "Step 6000, Loss: 731200.875, 예측 값: [1748.5015]\n",
      "Step 6500, Loss: 632535.9375, 예측 값: [1819.1906]\n",
      "Step 7000, Loss: 551758.625, 예측 값: [1883.1158]\n",
      "Step 7500, Loss: 485624.40625, 예측 값: [1940.9315]\n",
      "Step 8000, Loss: 431480.3125, 예측 값: [1993.2247]\n",
      "Step 8500, Loss: 387151.40625, 예측 값: [2040.5273]\n",
      "Step 9000, Loss: 350857.71875, 예측 값: [2083.3188]\n",
      "Step 9500, Loss: 321143.9375, 예측 값: [2122.0298]\n",
      "Step 10000, Loss: 296816.65625, 예측 값: [2157.0515]\n",
      "Step 10500, Loss: 276900.03125, 예측 값: [2188.7356]\n",
      "Step 11000, Loss: 260593.0625, 예측 값: [2217.4026]\n",
      "Step 11500, Loss: 247242.34375, 예측 값: [2243.3398]\n",
      "Step 12000, Loss: 236311.921875, 예측 값: [2266.807]\n",
      "Step 12500, Loss: 227362.71875, 예측 값: [2288.0403]\n",
      "Step 13000, Loss: 220035.8125, 예측 값: [2307.2527]\n",
      "Step 13500, Loss: 214036.71875, 예측 값: [2324.6372]\n",
      "Step 14000, Loss: 209125.015625, 예측 값: [2340.3674]\n",
      "Step 14500, Loss: 205103.328125, 예측 값: [2354.6018]\n",
      "Step 15000, Loss: 201811.015625, 예측 값: [2367.4802]\n",
      "Step 15500, Loss: 199115.09375, 예측 값: [2379.1345]\n",
      "Step 16000, Loss: 196907.984375, 예측 값: [2389.6794]\n",
      "Step 16500, Loss: 195100.78125, 예측 값: [2399.2212]\n",
      "Step 17000, Loss: 193621.03125, 예측 값: [2407.8557]\n",
      "Step 17500, Loss: 192409.0625, 예측 값: [2415.6716]\n",
      "Step 18000, Loss: 191417.09375, 예측 값: [2422.7405]\n",
      "Step 18500, Loss: 190604.40625, 예측 값: [2429.1406]\n",
      "Step 19000, Loss: 189939.359375, 예측 값: [2434.9285]\n",
      "Step 19500, Loss: 189394.3125, 예측 값: [2440.17]\n",
      "Step 20000, Loss: 188948.25, 예측 값: [2444.91]\n",
      "Step 20500, Loss: 188582.8125, 예측 값: [2449.2002]\n",
      "Step 21000, Loss: 188283.59375, 예측 값: [2453.082]\n",
      "Step 21500, Loss: 188038.359375, 예측 값: [2456.5964]\n",
      "Step 22000, Loss: 187837.375, 예측 값: [2459.7786]\n",
      "Step 22500, Loss: 187672.90625, 예측 값: [2462.6543]\n",
      "Step 23000, Loss: 187538.125, 예측 값: [2465.2568]\n",
      "Step 23500, Loss: 187427.5625, 예측 값: [2467.6145]\n",
      "Step 24000, Loss: 187336.703125, 예측 값: [2469.7544]\n",
      "Step 24500, Loss: 187262.796875, 예측 값: [2471.6755]\n",
      "Step 25000, Loss: 187201.515625, 예측 값: [2473.4329]\n",
      "Step 25500, Loss: 187151.796875, 예측 값: [2475.0054]\n",
      "Step 26000, Loss: 187110.84375, 예측 값: [2476.4338]\n",
      "Step 26500, Loss: 187077.15625, 예측 값: [2477.7285]\n",
      "Step 27000, Loss: 187049.453125, 예측 값: [2478.9006]\n",
      "Step 27500, Loss: 187026.625, 예측 값: [2479.9636]\n",
      "Step 28000, Loss: 187007.71875, 예측 값: [2480.934]\n",
      "Step 28500, Loss: 186992.390625, 예측 값: [2481.7969]\n",
      "Step 29000, Loss: 186979.78125, 예측 값: [2482.5752]\n",
      "Step 29500, Loss: 186968.90625, 예측 값: [2483.312]\n",
      "Step 30000, Loss: 186960.5625, 예측 값: [2483.9297]\n",
      "Step 30500, Loss: 186952.984375, 예측 값: [2484.5442]\n",
      "Step 31000, Loss: 186947.34375, 예측 값: [2485.039]\n",
      "Step 31500, Loss: 186942.21875, 예측 값: [2485.534]\n",
      "Step 32000, Loss: 186938.0625, 예측 값: [2485.9646]\n",
      "Step 32500, Loss: 186934.71875, 예측 값: [2486.3367]\n",
      "Step 33000, Loss: 186931.625, 예측 값: [2486.709]\n",
      "Step 33500, Loss: 186928.984375, 예측 값: [2487.0571]\n",
      "Step 34000, Loss: 186927.125, 예측 값: [2487.3066]\n",
      "Step 34500, Loss: 186925.390625, 예측 값: [2487.5564]\n",
      "Step 35000, Loss: 186923.78125, 예측 값: [2487.8057]\n",
      "Step 35500, Loss: 186922.296875, 예측 값: [2488.055]\n",
      "Step 36000, Loss: 186920.984375, 예측 값: [2488.2803]\n",
      "Step 36500, Loss: 186920.171875, 예측 값: [2488.4072]\n",
      "Step 37000, Loss: 186919.359375, 예측 값: [2488.534]\n",
      "Step 37500, Loss: 186918.578125, 예측 값: [2488.6606]\n",
      "Step 38000, Loss: 186917.859375, 예측 값: [2488.787]\n",
      "Step 38500, Loss: 186917.140625, 예측 값: [2488.9136]\n",
      "Step 39000, Loss: 186916.5, 예측 값: [2489.04]\n",
      "Step 39500, Loss: 186915.875, 예측 값: [2489.166]\n",
      "Step 40000, Loss: 186915.28125, 예측 값: [2489.2922]\n",
      "Step 40500, Loss: 186914.734375, 예측 값: [2489.4182]\n",
      "Step 41000, Loss: 186914.265625, 예측 값: [2489.5203]\n",
      "Step 41500, Loss: 186913.9375, 예측 값: [2489.524]\n",
      "Step 42000, Loss: 186913.578125, 예측 값: [2489.5276]\n",
      "Step 42500, Loss: 186913.25, 예측 값: [2489.5312]\n",
      "Step 43000, Loss: 186912.9375, 예측 값: [2489.535]\n",
      "Step 43500, Loss: 186912.625, 예측 값: [2489.5383]\n",
      "Step 44000, Loss: 186912.3125, 예측 값: [2489.5417]\n",
      "Step 44500, Loss: 186912.0, 예측 값: [2489.545]\n",
      "Step 45000, Loss: 186911.6875, 예측 값: [2489.5483]\n",
      "Step 45500, Loss: 186911.40625, 예측 값: [2489.5515]\n",
      "Step 46000, Loss: 186911.125, 예측 값: [2489.5547]\n",
      "Step 46500, Loss: 186910.84375, 예측 값: [2489.5579]\n",
      "Step 47000, Loss: 186910.5625, 예측 값: [2489.5608]\n",
      "Step 47500, Loss: 186910.296875, 예측 값: [2489.564]\n",
      "Step 48000, Loss: 186910.046875, 예측 값: [2489.5667]\n",
      "Step 48500, Loss: 186909.765625, 예측 값: [2489.5696]\n",
      "Step 49000, Loss: 186909.53125, 예측 값: [2489.5723]\n",
      "Step 49500, Loss: 186909.25, 예측 값: [2489.575]\n",
      "Step 50000, Loss: 186909.03125, 예측 값: [2489.578]\n",
      "Step 50500, Loss: 186908.78125, 예측 값: [2489.5803]\n",
      "Step 51000, Loss: 186908.53125, 예측 값: [2489.583]\n",
      "Step 51500, Loss: 186908.3125, 예측 값: [2489.5854]\n",
      "Step 52000, Loss: 186908.09375, 예측 값: [2489.5881]\n",
      "Step 52500, Loss: 186907.875, 예측 값: [2489.5906]\n",
      "Step 53000, Loss: 186907.640625, 예측 값: [2489.5928]\n",
      "Step 53500, Loss: 186907.4375, 예측 값: [2489.5952]\n",
      "Step 54000, Loss: 186907.234375, 예측 값: [2489.5977]\n",
      "Step 54500, Loss: 186907.03125, 예측 값: [2489.5999]\n",
      "Step 55000, Loss: 186906.84375, 예측 값: [2489.6023]\n",
      "Step 55500, Loss: 186906.625, 예측 값: [2489.6042]\n",
      "Step 56000, Loss: 186906.453125, 예측 값: [2489.6067]\n",
      "Step 56500, Loss: 186906.25, 예측 값: [2489.609]\n",
      "Step 57000, Loss: 186906.078125, 예측 값: [2489.6108]\n",
      "Step 57500, Loss: 186905.875, 예측 값: [2489.613]\n",
      "Step 58000, Loss: 186905.6875, 예측 값: [2489.6152]\n",
      "Step 58500, Loss: 186905.53125, 예측 값: [2489.617]\n",
      "Step 59000, Loss: 186905.359375, 예측 값: [2489.619]\n",
      "Step 59500, Loss: 186905.203125, 예측 값: [2489.621]\n",
      "Step 60000, Loss: 186905.0625, 예측 값: [2489.6228]\n",
      "Step 60500, Loss: 186904.875, 예측 값: [2489.6248]\n",
      "Step 61000, Loss: 186904.71875, 예측 값: [2489.627]\n",
      "Step 61500, Loss: 186904.5625, 예측 값: [2489.6284]\n",
      "Step 62000, Loss: 186904.40625, 예측 값: [2489.6304]\n",
      "Step 62500, Loss: 186904.265625, 예측 값: [2489.6323]\n",
      "Step 63000, Loss: 186904.109375, 예측 값: [2489.6338]\n",
      "Step 63500, Loss: 186903.96875, 예측 값: [2489.6355]\n",
      "Step 64000, Loss: 186903.828125, 예측 값: [2489.6375]\n",
      "Step 64500, Loss: 186903.703125, 예측 값: [2489.6392]\n",
      "Step 65000, Loss: 186903.578125, 예측 값: [2489.6406]\n",
      "Step 65500, Loss: 186903.4375, 예측 값: [2489.6423]\n",
      "Step 66000, Loss: 186903.3125, 예측 값: [2489.644]\n",
      "Step 66500, Loss: 186903.171875, 예측 값: [2489.6455]\n",
      "Step 67000, Loss: 186903.0625, 예측 값: [2489.647]\n",
      "Step 67500, Loss: 186902.9375, 예측 값: [2489.6487]\n",
      "Step 68000, Loss: 186902.8125, 예측 값: [2489.6501]\n",
      "Step 68500, Loss: 186902.703125, 예측 값: [2489.6514]\n",
      "Step 69000, Loss: 186902.578125, 예측 값: [2489.653]\n",
      "Step 69500, Loss: 186902.484375, 예측 값: [2489.6548]\n",
      "Step 70000, Loss: 186902.359375, 예측 값: [2489.6558]\n",
      "Step 70500, Loss: 186902.234375, 예측 값: [2489.657]\n",
      "Step 71000, Loss: 186902.140625, 예측 값: [2489.6587]\n",
      "Step 71500, Loss: 186902.03125, 예측 값: [2489.6602]\n",
      "Step 72000, Loss: 186901.9375, 예측 값: [2489.6611]\n",
      "Step 72500, Loss: 186901.84375, 예측 값: [2489.6624]\n",
      "Step 73000, Loss: 186901.71875, 예측 값: [2489.6638]\n",
      "Step 73500, Loss: 186901.640625, 예측 값: [2489.6653]\n",
      "Step 74000, Loss: 186901.5625, 예측 값: [2489.6663]\n",
      "Step 74500, Loss: 186901.46875, 예측 값: [2489.6672]\n",
      "Step 75000, Loss: 186901.34375, 예측 값: [2489.6687]\n",
      "Step 75500, Loss: 186901.28125, 예측 값: [2489.67]\n",
      "Step 76000, Loss: 186901.203125, 예측 값: [2489.671]\n",
      "Step 76500, Loss: 186901.109375, 예측 값: [2489.6719]\n",
      "Step 77000, Loss: 186901.015625, 예측 값: [2489.673]\n",
      "Step 77500, Loss: 186900.953125, 예측 값: [2489.6746]\n",
      "Step 78000, Loss: 186900.84375, 예측 값: [2489.6753]\n",
      "Step 78500, Loss: 186900.78125, 예측 값: [2489.6763]\n",
      "Step 79000, Loss: 186900.71875, 예측 값: [2489.6772]\n",
      "Step 79500, Loss: 186900.640625, 예측 값: [2489.6785]\n",
      "Step 80000, Loss: 186900.5625, 예측 값: [2489.6794]\n",
      "Step 80500, Loss: 186900.484375, 예측 값: [2489.6802]\n",
      "Step 81000, Loss: 186900.40625, 예측 값: [2489.681]\n",
      "Step 81500, Loss: 186900.34375, 예측 값: [2489.6821]\n",
      "Step 82000, Loss: 186900.265625, 예측 값: [2489.6833]\n",
      "Step 82500, Loss: 186900.203125, 예측 값: [2489.684]\n",
      "Step 83000, Loss: 186900.15625, 예측 값: [2489.6846]\n",
      "Step 83500, Loss: 186900.078125, 예측 값: [2489.6855]\n",
      "Step 84000, Loss: 186900.015625, 예측 값: [2489.6865]\n",
      "Step 84500, Loss: 186899.921875, 예측 값: [2489.6875]\n",
      "Step 85000, Loss: 186899.890625, 예측 값: [2489.6882]\n",
      "Step 85500, Loss: 186899.84375, 예측 값: [2489.6887]\n",
      "Step 86000, Loss: 186899.765625, 예측 값: [2489.6895]\n",
      "Step 86500, Loss: 186899.734375, 예측 값: [2489.6904]\n",
      "Step 87000, Loss: 186899.640625, 예측 값: [2489.6914]\n",
      "Step 87500, Loss: 186899.59375, 예측 값: [2489.692]\n",
      "Step 88000, Loss: 186899.546875, 예측 값: [2489.6924]\n",
      "Step 88500, Loss: 186899.5, 예측 값: [2489.693]\n",
      "Step 89000, Loss: 186899.4375, 예측 값: [2489.6938]\n",
      "Step 89500, Loss: 186899.375, 예측 값: [2489.6946]\n",
      "Step 90000, Loss: 186899.328125, 예측 값: [2489.6956]\n",
      "Step 90500, Loss: 186899.296875, 예측 값: [2489.6958]\n",
      "Step 91000, Loss: 186899.25, 예측 값: [2489.6963]\n",
      "Step 91500, Loss: 186899.1875, 예측 값: [2489.697]\n",
      "Step 92000, Loss: 186899.15625, 예측 값: [2489.6978]\n",
      "Step 92500, Loss: 186899.09375, 예측 값: [2489.6985]\n",
      "Step 93000, Loss: 186899.0625, 예측 값: [2489.699]\n",
      "Step 93500, Loss: 186899.015625, 예측 값: [2489.6995]\n",
      "Step 94000, Loss: 186898.96875, 예측 값: [2489.6997]\n",
      "Step 94500, Loss: 186898.921875, 예측 값: [2489.7004]\n",
      "Step 95000, Loss: 186898.875, 예측 값: [2489.701]\n",
      "Step 95500, Loss: 186898.84375, 예측 값: [2489.7017]\n",
      "Step 96000, Loss: 186898.796875, 예측 값: [2489.7021]\n",
      "Step 96500, Loss: 186898.765625, 예측 값: [2489.7024]\n",
      "Step 97000, Loss: 186898.71875, 예측 값: [2489.703]\n",
      "Step 97500, Loss: 186898.6875, 예측 값: [2489.7031]\n",
      "Step 98000, Loss: 186898.640625, 예측 값: [2489.7036]\n",
      "Step 98500, Loss: 186898.609375, 예측 값: [2489.704]\n",
      "Step 99000, Loss: 186898.578125, 예측 값: [2489.7046]\n",
      "Step 99500, Loss: 186898.546875, 예측 값: [2489.7048]\n",
      "Step 100000, Loss: 186898.5, 예측 값: [2489.705]\n",
      "학습된 모델을 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 학습 루프\n",
    "for step in range(100001):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = cost_fn(x_data, y_data)\n",
    "    \n",
    "    gradients = tape.gradient(cost, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(f\"Step {step}, Loss: {cost.numpy()}, 예측 값: {hypothesis(x_data).numpy()[0]}\")\n",
    "\n",
    "# 학습된 모델 저장\n",
    "ckpt = tf.train.Checkpoint(W=W, b=b)\n",
    "ckpt.save(\"./saved.ckpt\")\n",
    "print(\"학습된 모델을 저장했습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
